{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/teamspace/studios/this_studio/hfcache\n"
     ]
    }
   ],
   "source": [
    "env HF_HOME=/teamspace/studios/this_studio/hfcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "device = \"cuda\"\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc9796b1c714dafa0bea36f4ed85967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": dtype},\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As I reflect on my childhood, I'm drawn to the warmth and love of my mother's presence. Her loving gaze and gentle smile evoke feelings of security, peace, and a sense of oneness with the universe. In this state, I'm transported to a place of relaxation and ecstasy, where I feel a vortex of cosmic energy coursing through me, connecting me to the entire universe and all its wonders.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"To bring these moments of life to my present, I need to deeply return to my senses.\n",
    "For some reason I remember my mother's face, my mother from that time, smiling, happy, a loving look, and welcoming.\n",
    "Her big blue eyes and her hair were much darker than what she had worn the last few years.\n",
    "She always sang to me, I have her melodies saved in a soft sound, as a backdrop to my unconscious.\n",
    "Sensations of love, security, peace, and an infinite ignorance of the smallness of my form, of the grain of sand that is planet Earth in the endless cosmos.\n",
    "The pleasure of having no scale of oneself, of becoming one with the mother, feeling those curious glances towards you, and that there is no egoic reflection that modifies the naivety of their facial expressions.\\nA pleasure that rests in the present, that welcomes the comfort of being in the arms of someone who swears to protect you through her loving gaze.\\nAll of this can evoke in me a relaxation, almost an ecstasy of calm.\\nI can feel on the top of my head how there is a vortex of cosmic energy, so strong that it does not allow me to land on matter yet and capture a sense of identity in it.\\nI perceive colors, like a mixed plasticine, in which the pure colors can still be distinguished, but they are so intertwined that they generate new shadows, tones and nuances from the apparent mixture of all of them. This colorful channel contains the entire universe, on all its scales.\n",
    "A cascade of information of all densities, with the capacity to nourish with the necessary information, to spin each cell of this living being that\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"You are an expert at summarizing text into two or three sentences. Summarize anything you are given, only answer with the summary of the last text given.\n",
    "When summarizing, anaswer in the first person as if you were the author. Convey what the author was expressing, what was the core idea or sentiment, emotion evoked? What were they trying to communicate in their meditation?\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
